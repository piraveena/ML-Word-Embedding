# CS4622 Word-Embedding

Natural Language Processing(NLP) is a wide research area where much research efforts in the recent years have been taking place. Word embedding is one of the strongest trends nowadays in NLP. Word Embedding , plays an important role in building word vectors for words based on their contexts in a corpus, which captures both semantic and syntactic information of words. Word embeddings represent the meaning of a word as a real-valued vector  

## Methodology  
    1. Collecting corpus  
  	2. Preprocessing  
    3. Model training  
    4. Evaluation  

## Datasets used for evaluations  
    1. WS-353-Sim - Agirre et. al, 2009 (http://alfonseca.org/eng/research/wordsim353.html)    
    2. MC-30 - Miller and Charles, 1991 (http://www.tandfonline.com/doi/abs/10.1080/01690969108406936#.Uu_392SwIyV)  
    3. RG-65 -  R and G, 1965 (http://dl.acm.org/citation.cfm?id=365657)     
